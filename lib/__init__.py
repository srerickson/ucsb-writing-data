import duckdb
from pathlib import Path
import pandas as pd
from sentence_transformers import SentenceTransformer
from openai import OpenAI
from IPython.display import Markdown as md, display
from textwrap import dedent

# load the model for computing embeddings for query string
mxbai = SentenceTransformer("mixedbread-ai/mxbai-embed-large-v1")

# embeddings for the text responses in the survey data have been pre-computed

# non-normalized mxbai embeddings
# (these were generated by ollama before it supported normalization of mxbain embeddings)
mxbai_nonnorm_url = "https://dreamlab-public.s3.us-west-2.amazonaws.com/sorapure/mxbai_embeddings_nonnorm.parquet"
mxbai_nonnorm_file = Path("outputs") / 'mxbai_embeddings_nonnorm.parquet'

# normalized mxbai embeddings
mxbai_norm_url = "https://dreamlab-public.s3.us-west-2.amazonaws.com/sorapure/mxbai_embeddings_norm.parquet"
mxbai_norm_file = Path("outputs") / 'mxbai_embeddings_norm.parquet'

# openai embeddings (noramlized)
openai_url = "https://dreamlab-public.s3.us-west-2.amazonaws.com/sorapure/openai_3small.parquet"
openai_file = Path("outputs") / 'openai_3small.parquet'

def search_display(q: str, df: pd.DataFrame, limit: int = 25, model: str = "mxbai"):
    result = search_df(q, df, limit=limit, model=model)
    for i, row in result.iterrows():
        text = f"(distance: {str(row['result_distance'])[:4]}, perm: {row['perm']}) {row['result_text']}"
        display(md(text))


def search_df(q: str, df: pd.DataFrame, limit: int = 25, model: str = "openai") -> pd.DataFrame:
    if model == "mxbai":
       # stay combatible with old behavior: 'mxbai' refers to non-normalized data
       return mxbai_search_df(q, df, limit, normalize=False)
    if model == "mxbai_norm":
       return mxbai_search_df(q, df, limit, normalize=True)
    return openai_search_df(q, df, limit=limit)


def openai_search_df(q: str, df: pd.DataFrame, limit: int = 25) -> pd.DataFrame:
    if not mxbai_norm_file.exists():
        duckdb.execute(f"COPY (SELECT * from read_parquet('{openai_url}')) TO '{openai_file}' (FORMAT PARQUET);")
    client = OpenAI()
    response =  client.embeddings.create(input=q,model="text-embedding-3-small")
    query_embed = response.data[0].embedding
    sql = f"""
        FROM df
        LEFT JOIN read_parquet('{openai_file}') ON (df.perm = student_id)
        SELECT 
            df.*,
            embedding,
            question_id as result_question_id,
            array_distance(
                CAST(embedding as FLOAT[1536]),
                CAST($embed as FLOAT[1536])
            ) AS result_distance
        ORDER BY result_distance ASC
    """
    if limit > 0:
        sql += f" LIMIT {limit};"
    else:
        sql += ";"
    result = duckdb.execute(sql, {"embed": query_embed}).fetch_df()
    result['result_text'] = result.apply(lambda row: row[row['result_question_id']], axis=1)
    return result


def openai_completion(template: str, question: str, context: pd.DataFrame, model: str = "gpt-4o-mini") -> str:
    context = "\n\n".join(context["result_text"])
    client = OpenAI()
    prompt = template.format(context=context, question=question)
    completion = client.chat.completions.create(
        model = model,
        messages=[
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user","content": prompt}
        ])
    return completion.choices[0].message.content

def mxbai_search_df(q: str, df: pd.DataFrame, limit: int = 25, normalize: bool = True) -> pd.DataFrame:
    use_file = mxbai_norm_file
    use_url = mxbai_norm_url
    if not normalize:
        use_file = mxbai_nonnorm_file
        use_url = mxbai_nonnorm_url
    if not use_file.exists():
        duckdb.execute(f"COPY (SELECT * from read_parquet('{use_url}')) TO '{use_file}' (FORMAT PARQUET);")
    query = f"Represent this sentence for searching relevant passages: {q}"
    query_embed = mxbai.encode(query, normalize_embeddings = normalize)
    sql = f"""
        FROM df
        LEFT JOIN read_parquet('{use_file}') ON (df.perm = student_id)
        SELECT 
            df.*,
            embedding,
            question_id as result_question_id,
            array_distance(
                CAST(embedding as FLOAT[1024]),
                CAST($embed as FLOAT[1024])
            ) AS result_distance
        ORDER BY result_distance ASC
    """
    if limit > 0:
        sql += f" LIMIT {limit};"
    else:
        sql += ";"
    result = duckdb.execute(sql, {"embed": query_embed}).fetch_df()
    result['result_text'] = result.apply(lambda row: row[row['result_question_id']], axis=1)
    return result